linear_accuracy)
linear_norm <- lm(X1 ~ X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10 + X11 + X12 + X13 + X14 + X15 + X16 + X17 + X18 + X19 + X20 + X21, data=hsbc_train)
summary(linear_norm)
resettest(linear_norm)
linear_predicted <- predict.lm(linear, newdata = data.frame(hsbc_test)) %>%
ReverseNorm()
linear_accuracy <- forecast::accuracy(linear_predicted, y_test)
linear_accuracy
rf <- randomForest(X_train, y_train,
xtest=X_val, ytest=y_val,
keep.forest = TRUE)
rf_cv <- rf.crossValidation(rf, X_train, y_train,
bootstrap=FALSE, xtest=data.frame(X_val), ytest=y_val,
keep.forest = TRUE)
rf_cv_predicted <- predict(rf, X_test) %>%
ReverseNorm()
rf_accuracy <- forecast::accuracy(rf_cv_predicted, y_test)
rf_accuracy
?rf.crossValidation()
rf_log_diff <- randomForest(X_log_diff_train, y_log_diff_train,
xtest=X_log_diff_val, ytest=y_Log_diff_val,
keep.forest = TRUE)
rf_log_diff <- randomForest(X_log_diff_train, y_log_diff_train,
xtest=X_log_diff_val, ytest=y_log_diff_val,
keep.forest = TRUE)
rf_cv_log_diff <- rf.crossValidation(rf, X_log_diff_train, y_log_diff_train,
bootstrap=FALSE, xtest=data.frame(X_log_diff_val), ytest=y_log_diff_val,
keep.forest = TRUE)
rf_cv_log_diff_predicted <- predict(rf, X_log_diff_test) %>%
ReverseNorm()
rf_log_diff_accuracy <- forecast::accuracy(rf_cv_Log_diff_predicted, y_test)
rf_log_diff_accuracy <- forecast::accuracy(rf_cv_log_diff_predicted, y_log_diff_test)
rf_log_diff_accuracy
xgb_norm_tuned <- xgboost(data=X_train,
label=y_train,
nrounds=120,
params=list(eta=0.5,
max_depth=8,
subsample=0.4,
n_estimators=250))
xgb_norm_predicted <- predict(xgb_norm_tuned, X_test) %>%
ReverseNorm()
xgb_accuracy <- forecast::accuracy(xgb_tuned_predicted, y_test)
xgb_accuracy
xgb_norm_tuned <- xgboost(data=X_train,
label=y_train,
nrounds=200,
params=list(eta=0.5,
max_depth=8,
subsample=0.4,
n_estimators=250))
xgb_norm_predicted <- predict(xgb_norm_tuned, X_test) %>%
ReverseNorm()
xgb_accuracy <- forecast::accuracy(xgb_tuned_predicted, y_test)
xgb_accuracy
xgb_norm_tuned <- xgboost(data=X_train,
label=y_train,
nrounds=30,
params=list(eta=0.5,
max_depth=8,
subsample=0.4,
n_estimators=250))
xgb_norm_predicted <- predict(xgb_norm_tuned, X_test) %>%
ReverseNorm()
xgb_accuracy <- forecast::accuracy(xgb_tuned_predicted, y_test)
xgb_accuracy
xgb_norm_tuned <- xgboost(data=X_train,
label=y_train,
nrounds=200,
params=list(eta=0.5,
max_depth=8,
subsample=0.4,
n_estimators=250))
xgb_log_diff_tuned <- xgboost(data=X_log_diff_train,
label=y_log_diff_train,
nrounds=200,
params=list(eta=0.5,
max_depth=8,
subsample=0.4,
n_estimators=250))
xgb_log_diff_predicted <- predict(xgb_log_diff_tuned, X_log_diff_test) %>%
ReverseNorm()
xgb_log_diff_accuracy <- forecast::accuracy(xgb_log_diff_predicted, y_log_diff_test)
xgb_log_diff_accuracy
xgb_log_diff_tuned <- xgboost(data=X_log_diff_train,
label=y_log_diff_train,
nrounds=150,
params=list(eta=0.5,
max_depth=8,
subsample=0.4,
n_estimators=250))
xgb_log_diff_tuned <- xgboost(data=X_log_diff_train,
label=y_log_diff_train,
nrounds=150,
params=list(eta=0.5,
max_depth=8,
subsample=0.4,
n_estimators=250))
xgb_log_diff_predicted <- predict(xgb_log_diff_tuned, X_log_diff_test) %>%
ReverseNorm()
xgb_log_diff_accuracy <- forecast::accuracy(xgb_log_diff_predicted, y_log_diff_test)
xgb_log_diff_accuracy
lstm_parameters <- list(units=seq(from=4, to=16, by=2),
dropout=seq(from=0.2, to=0.6, by=0.1))
runs <- tuning_run("lstm.R", flags=lstm_parameters, sample=0.5)
# Run once for installation
# Quandl API key: rTCfeqfv2pbfQG-uk-af
# install.packages("Quandl")
# install.packages("keras")
# install_keras()
# install.packages("tensorflow")
# install.packages("tsibble")
# install.packages("randomforest")
# install.packages("forecast")
# install.packages("aTSA)
# install.packages("xgboost")
# install.packages("superml")
# install.packages("rfUtilities")
# install.packages("gridExtra")
# install.packages("ggplotify")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # For loading the generally needed packages, dplyr, ggplot2 etc
library(tsibble) # Extension of the tidyverse to time-series data
library(Quandl) # API for downloading the data
library(keras) # For Artificial Neural Network
library(randomForest) # To implement random forests
library(forecast) # To assess predictions and compare them to the real test set
library(aTSA) #Useful for time series analysis
library(xgboost) # For gradient boosted random forests
#library(e1071) # For
library(superml) # For cross validation of the XGB model
library(lmtest) # For testing the basic, linear model
library(rfUtilities) #For cross validation of the random forest
library(gridExtra)
library(ggplotify)
set.seed(177125)
runs <- tuning_run("lstm.R", flags=lstm_parameters, sample=0.5)
runs <- tensorflow::tuning_run("lstm.R", flags=lstm_parameters, sample=0.5)
runs <- tfruns::tuning_run("lstm.R", flags=lstm_parameters, sample=0.5)
best_run <- ls_runs(order=metric_val_loss, decreasing=FALSE)[1,]
ls_runs(order=metric_val_loss, decreasing=FALSE)
best_run <- tfruns::ls_runs(order=metric_val_loss, decreasing=FALSE)[1,]
run <- training_run('lstm.R',flags = list(dropout = best_run$flag_dropout,
units = best_run$flag_units))
run <- tfruns::training_run('lstm.R',flags = list(dropout = best_run$flag_dropout,
units = best_run$flag_units))
best_model_norm <- load_model_hdf5('lstm.h5')
best_model_norm %>% compile(optimizer="nadam", loss="mean_squared_error")
best_model_norm_training <- best_model %>% fit(x=X_train_lstm,
y=y_train,
batch_size=32,
epochs=100,
validation_data=val_list,
shuffle=FALSE)
best_model_norm_training <- best_model %>% fit(x=X_train_lstm,
y=y_train,
batch_size=32,
epochs=100,
validation_data=val_list,
shuffle=FALSE)
best_model_norm_training <- best_model_norm %>% fit(x=X_train_lstm,
y=y_train,
batch_size=32,
epochs=100,
validation_data=val_list,
shuffle=FALSE)
lstm_norm_predicted <- predict(best_model_norm, X_test_lstm) %>%
ReverseNorm()
lstm_norm_accuracy <- forecast::accuracy(lstm_norm_predicted, y_test)
lstm_norm_accuracy <- forecast::accuracy(lstm_norm_predicted, y_test)
lstm_norm_accuracy <- forecast::accuracy(as.ts(lstm_norm_predicted), y_test)
print(lstm_accuracy)
best_model_norm_training <- best_model_norm %>% fit(x=X_train_lstm,
y=y_train,
batch_size=32,
epochs=200,
validation_data=val_list,
shuffle=FALSE)
lstm_norm_predicted <- predict(best_model_norm, X_test_lstm) %>%
ReverseNorm()
lstm_norm_accuracy <- forecast::accuracy(as.ts(lstm_norm_predicted), y_test)
print(lstm_accuracy)
runs <- tfruns::tuning_run("lstm_log_diff.R", flags=lstm_parameters, sample=0.5)
best_run <- tfruns::ls_runs(order=metric_val_loss, decreasing=FALSE)[1,]
run <- tfruns::training_run('lstm_log_diff.R',flags = list(dropout = best_run$flag_dropout,
units = best_run$flag_units))
best_model_log_diff <- load_model_hdf5('lstm_log_diff.h5')
best_model_log_diff %>% compile(optimizer="nadam", loss="mean_squared_error")
best_model_log_diff_training <- best_model_log_diff %>% fit(x=X_log_diff_train_lstm,
y=y_log_diff_train,
batch_size=32,
epochs=200,
validation_data=val_log_diff_list,
shuffle=FALSE)
lstm_log_diff_predicted <- predict(best_model_log_diff, X_log_diff_test_lstm) %>%
ReverseNorm()
lstm_norm_accuracy <- forecast::accuracy(as.ts(lstm_log_diff_predicted), y_test)
lstm_norm_accuracy <- forecast::accuracy(as.ts(lstm_log_diff_predicted), y_log_diff_test)
print(lstm_accuracy)
results <- data.frame(cbind(y_test, linear_predicted))
names(results)[1] <- "actual"
results <- data.frame(cbind(results, rf_cv_predicted))
results <- data.frame(cbind(results, rf_cv_log_diff_predicted))
results <- data.frame(cbind(y_test, linear_predicted))
names(results)[1] <- "actual"
results <- data.frame(cbind(results, rf_cv_predicted))
results <- data.frame(cbind(results, xgb_norm_predicted))
results <- data.frame(cbind(results, lstm_norm_predicted))
results <- results[-1, ]
results <- data.frame(cbind(results, rf_cv_log_diff_predicted))
results <- data.frame(cbind(results, xgb_log_diff_predicted))
results <- data.frame(cbind(results, lstm_log_diff_predicted))
results <- data.frame(cbind(y_test, linear_predicted))
names(results)[1] <- "actual"
results <- data.frame(cbind(results, rf_cv_predicted))
results <- data.frame(cbind(results, xgb_norm_predicted))
results <- data.frame(cbind(results, lstm_norm_predicted))
results <- results[-1, ]
results <- data.frame(cbind(results, rf_cv_log_diff_predicted))
results <- data.frame(cbind(results, xgb_log_diff_predicted))
results <- data.frame(cbind(results, lstm_log_diff_predicted))
results$timesteps <- as.numeric(row.names(results))
head(results)
results <- data.frame(cbind(y_test,
linear_predicted,
rf_cv_predicted,
xgb_norm_predicted,
lstm_norm_predicted))
names(results)[1] <- "actual"
results <- results[-1, ]
results <- data.frame(cbind(results,
rf_cv_log_diff_predicted,
xgb_log_diff_predicted,
lstm_log_diff_predicted))
results$timesteps <- as.numeric(row.names(results))
print(lstm_norm_accuracy)
lstm_log_diff_predicted <- predict(best_model_log_diff, X_log_diff_test_lstm) %>%
ReverseNorm()
lstm_log_diff_accuracy <- forecast::accuracy(as.ts(lstm_log_diff_predicted), y_log_diff_test)
print(lstm_log_diff_accuracy)
best_model_norm_training <- best_model_norm %>% fit(x=X_train_lstm,
y=y_train,
batch_size=32,
epochs=200,
validation_data=val_list,
shuffle=FALSE)
lstm_norm_predicted <- predict(best_model_norm, X_test_lstm) %>%
ReverseNorm()
lstm_norm_accuracy <- forecast::accuracy(as.ts(lstm_norm_predicted), y_test)
print(lstm_norm_accuracy)
best_model_norm_training <- best_model_norm %>% fit(x=X_train_lstm,
y=y_train,
batch_size=32,
epochs=300,
validation_data=val_list,
shuffle=FALSE)
lstm_norm_predicted <- predict(best_model_norm, X_test_lstm) %>%
ReverseNorm()
lstm_norm_accuracy <- forecast::accuracy(as.ts(lstm_norm_predicted), y_test)
print(lstm_norm_accuracy)
best_model_norm_training <- best_model_norm %>% fit(x=X_train_lstm,
y=y_train,
batch_size=64,
epochs=300,
validation_data=val_list,
shuffle=FALSE)
lstm_norm_predicted <- predict(best_model_norm, X_test_lstm) %>%
ReverseNorm()
lstm_norm_accuracy <- forecast::accuracy(as.ts(lstm_norm_predicted), y_test)
print(lstm_norm_accuracy)
best_model_norm_training <- best_model_norm %>% fit(x=X_train_lstm,
y=y_train,
batch_size=128,
epochs=50,
validation_data=val_list,
shuffle=FALSE)
lstm_norm_predicted <- predict(best_model_norm, X_test_lstm) %>%
ReverseNorm()
lstm_norm_accuracy <- forecast::accuracy(as.ts(lstm_norm_predicted), y_test)
print(lstm_norm_accuracy)
best_model_norm_training <- best_model_norm %>% fit(x=X_train_lstm,
y=y_train,
batch_size=128,
epochs=300,
validation_data=val_list,
shuffle=FALSE)
lstm_norm_predicted <- predict(best_model_norm, X_test_lstm) %>%
ReverseNorm()
lstm_norm_accuracy <- forecast::accuracy(as.ts(lstm_norm_predicted), y_test)
print(lstm_norm_accuracy)
best_model_norm_training <- best_model_norm %>% fit(x=X_train_lstm,
y=y_train,
batch_size=16,
epochs=10,
validation_data=val_list,
shuffle=FALSE)
lstm_norm_predicted <- predict(best_model_norm, X_test_lstm) %>%
ReverseNorm()
lstm_norm_accuracy <- forecast::accuracy(as.ts(lstm_norm_predicted), y_test)
print(lstm_norm_accuracy)
best_model_norm_training <- best_model_norm %>% fit(x=X_train_lstm,
y=y_train,
batch_size=256,
epochs=100,
validation_data=val_list,
shuffle=FALSE)
lstm_norm_predicted <- predict(best_model_norm, X_test_lstm) %>%
ReverseNorm()
lstm_norm_accuracy <- forecast::accuracy(as.ts(lstm_norm_predicted), y_test)
print(lstm_norm_accuracy)
best_model_norm_training <- best_model_norm %>% fit(x=X_train_lstm,
y=y_train,
batch_size=512,
epochs=100,
validation_data=val_list,
shuffle=FALSE)
lstm_norm_predicted <- predict(best_model_norm, X_test_lstm) %>%
ReverseNorm()
lstm_norm_accuracy <- forecast::accuracy(as.ts(lstm_norm_predicted), y_test)
print(lstm_norm_accuracy)
best_model_norm_training <- best_model_norm %>% fit(x=X_train_lstm,
y=y_train,
batch_size=128,
epochs=500,
validation_data=val_list,
shuffle=FALSE)
lstm_norm_predicted <- predict(best_model_norm, X_test_lstm) %>%
ReverseNorm()
lstm_norm_accuracy <- forecast::accuracy(as.ts(lstm_norm_predicted), y_test)
print(lstm_norm_accuracy)
best_model_log_diff_training <- best_model_log_diff %>% fit(x=X_log_diff_train_lstm,
y=y_log_diff_train,
batch_size=128,
epochs=100,
validation_data=val_log_diff_list,
shuffle=FALSE)
lstm_log_diff_predicted <- predict(best_model_log_diff, X_log_diff_test_lstm) %>%
ReverseNorm()
lstm_log_diff_accuracy <- forecast::accuracy(as.ts(lstm_log_diff_predicted), y_log_diff_test)
print(lstm_log_diff_accuracy)
accuracies <- data.frame(rbind(linear_accuracy,
rf_accuracy,
rf_log_diff_accuracy,
xgb_accuracy,
xgb_log_diff_accuracy,,
lstm_norm_accuracy,
lstm_log_diff_accuracy))
accuracies <- data.frame(rbind(linear_accuracy,
rf_accuracy,
rf_log_diff_accuracy,
xgb_accuracy,
xgb_log_diff_accuracy,
lstm_norm_accuracy,
lstm_log_diff_accuracy))
accuracies
accuracies <- data.frame(rbind(linear_accuracy,
rf_accuracy,
rf_log_diff_accuracy,
xgb_accuracy,
xgb_log_diff_accuracy,
lstm_norm_accuracy,
lstm_log_diff_accuracy))
rownames(accuracies <- c("Linear Model",
"Random Forest w/ Normalised Data",
"Random Forest w/ Differenced Data",
"Gradient Boosted Random Forest w/ Normalised Data",
"Gradient Boosted Random Forest w/ Differenced Data",
"Recurrent Neural Network w/ Normalised Data",
"Recurrent Neural Network w/ Differenced Data"))
print(accuracies)
accuracies <- data.frame(rbind(linear_accuracy,
rf_accuracy,
rf_log_diff_accuracy,
xgb_accuracy,
xgb_log_diff_accuracy,
lstm_norm_accuracy,
lstm_log_diff_accuracy))
rownames(accuracies) <- c("Linear Model",
"Random Forest w/ Normalised Data",
"Random Forest w/ Differenced Data",
"Gradient Boosted Random Forest w/ Normalised Data",
"Gradient Boosted Random Forest w/ Differenced Data",
"Recurrent Neural Network w/ Normalised Data",
"Recurrent Neural Network w/ Differenced Data")
print(accuracies)
ggplot(data=results) +
geom_line(mapping=aes(x=timesteps, y=actual, colour="black")) +
geom_line(mapping=aes(x=timesteps, y=linear_predicted, colour="red")) +
geom_line(mapping=aes(x=timesteps, y=rf_cv_predicted, colour="blue")) +
geom_line(mapping=aes(x=timesteps, y=xgb_norm_predicted, colour="green")) +
geom_line(mapping=aes(x=timesteps, y=lstm_norm_predicted, colour="yellow"))
ggplot(data=results) +
geom_line(mapping=aes(x=timesteps, y=actual[-1], colour="black")) +
geom_line(mapping=aes(x=timesteps, y=linear_predicted[-1], colour="red")) +
geom_line(mapping=aes(x=timesteps, y=rf_cv_predicted[-1], colour="blue")) +
geom_line(mapping=aes(x=timesteps, y=xgb_norm_predicted[-1], colour="green")) +
geom_line(mapping=aes(x=timesteps, y=lstm_norm_predicted[-1], colour="yellow"))
ggplot(data=results) +
#  geom_line(mapping=aes(x=timesteps, y=actual[-1], colour="black")) +
#  geom_line(mapping=aes(x=timesteps, y=linear_predicted[-1], colour="red")) +
#  geom_line(mapping=aes(x=timesteps, y=rf_cv_predicted[-1], colour="blue")) +
#  geom_line(mapping=aes(x=timesteps, y=xgb_norm_predicted[-1], colour="green")) +
geom_line(mapping=aes(x=timesteps, y=lstm_norm_predicted[-1], colour="yellow"))
ggplot(data=results) +
#  geom_line(mapping=aes(x=timesteps, y=actual[-1], colour="black")) +
#  geom_line(mapping=aes(x=timesteps, y=linear_predicted[-1], colour="red")) +
#  geom_line(mapping=aes(x=timesteps, y=rf_cv_predicted[-1], colour="blue")) +
geom_line(mapping=aes(x=timesteps, y=xgb_norm_predicted[-1], colour="green")) +
geom_line(mapping=aes(x=timesteps, y=lstm_norm_predicted[-1], colour="yellow"))
ggplot(data=results) +
#  geom_line(mapping=aes(x=timesteps, y=actual[-1], colour="black")) +
#  geom_line(mapping=aes(x=timesteps, y=linear_predicted[-1], colour="red")) +
#  geom_line(mapping=aes(x=timesteps, y=rf_cv_predicted[-1], colour="blue")) +
geom_line(mapping=aes(x=timesteps, y=xgb_norm_predicted, colour="green")) +
geom_line(mapping=aes(x=timesteps, y=lstm_norm_predicted[-1], colour="yellow"))
ggplot(data=results) +
#  geom_line(mapping=aes(x=timesteps, y=actual[-1], colour="black")) +
#  geom_line(mapping=aes(x=timesteps, y=linear_predicted[-1], colour="red")) +
geom_line(mapping=aes(x=timesteps, y=rf_cv_predicted[-1], colour="blue")) +
geom_line(mapping=aes(x=timesteps, y=xgb_norm_predicted, colour="green")) +
geom_line(mapping=aes(x=timesteps, y=lstm_norm_predicted[-1], colour="yellow"))
ggplot(data=results) +
#  geom_line(mapping=aes(x=timesteps, y=actual[-1], colour="black")) +
#  geom_line(mapping=aes(x=timesteps, y=linear_predicted[-1], colour="red")) +
geom_line(mapping=aes(x=timesteps, y=rf_cv_predicted, colour="blue")) +
geom_line(mapping=aes(x=timesteps, y=xgb_norm_predicted, colour="green")) +
geom_line(mapping=aes(x=timesteps, y=lstm_norm_predicted[-1], colour="yellow"))
ggplot(data=results) +
#  geom_line(mapping=aes(x=timesteps, y=actual[-1], colour="black")) +
geom_line(mapping=aes(x=timesteps, y=linear_predicted, colour="red")) +
geom_line(mapping=aes(x=timesteps, y=rf_cv_predicted, colour="blue")) +
geom_line(mapping=aes(x=timesteps, y=xgb_norm_predicted, colour="green")) +
geom_line(mapping=aes(x=timesteps, y=lstm_norm_predicted[-1], colour="yellow"))
ggplot(data=results) +
geom_line(mapping=aes(x=timesteps, y=actual[-1], colour="black")) +
geom_line(mapping=aes(x=timesteps, y=linear_predicted, colour="red")) +
geom_line(mapping=aes(x=timesteps, y=rf_cv_predicted, colour="blue")) +
geom_line(mapping=aes(x=timesteps, y=xgb_norm_predicted, colour="green")) +
geom_line(mapping=aes(x=timesteps, y=lstm_norm_predicted[-1], colour="yellow"))
ggplot(data=results) +
geom_line(mapping=aes(x=timesteps, y=actual, colour="black")) +
geom_line(mapping=aes(x=timesteps, y=linear_predicted, colour="red")) +
geom_line(mapping=aes(x=timesteps, y=rf_cv_predicted, colour="blue")) +
geom_line(mapping=aes(x=timesteps, y=xgb_norm_predicted, colour="green")) +
geom_line(mapping=aes(x=timesteps, y=lstm_norm_predicted[-1], colour="yellow"))
ggplot(data=results) +
geom_line(mapping=aes(x=timesteps, y=actual, colour="Actual")) +
geom_line(mapping=aes(x=timesteps, y=linear_predicted, colour="Linear")) +
geom_line(mapping=aes(x=timesteps, y=rf_cv_predicted, colour="Random Forest")) +
geom_line(mapping=aes(x=timesteps, y=xgb_norm_predicted, colour="XGB")) +
geom_line(mapping=aes(x=timesteps, y=lstm_norm_predicted[-1], colour="ANN"))
# Create a function to fill missing values in the time series (due to weekends/bank holidays etc).
# Each NA value is replaced with the previous close price of the series. This is the price that market
# participants would see when making trading decisions on days where the exchange was closed.
ImputeMissing <- function(ts){
df <- data.frame(ts)
for(i in 1:nrow(df)){
if(is.na(df[i, 1])){
df[i, 1] <- df[i-1, 1]
}
}
dates_formatted <- data.frame(dates)
df <- cbind(df, dates_formatted)
names(df)[1] <- "Price"
names(df)[2] <- "Date"
tib_new <- as_tsibble(df, index="Date")
return(tib_new)
}
hsbc_tib <- ImputeMissing(hsbc_ts)
hsbc_ts <- as.ts(hsbc_tib, start = c(2014, as.numeric(format(dates[1], "%j"))), frequency=365)
knitr::opts_chunk$set(echo = TRUE)
# Run once for installation
# Quandl API key: rTCfeqfv2pbfQG-uk-af
# install.packages("Quandl")
# install.packages("keras")
# install_keras()
# install.packages("tensorflow")
# install.packages("tsibble")
# install.packages("randomforest")
# install.packages("forecast")
# install.packages("aTSA)
# install.packages("xgboost")
# install.packages("superml")
# install.packages("rfUtilities")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # For loading the generally needed packages, dplyr, ggplot2 etc
library(tsibble) # Extension of the tidyverse to time-series data
library(Quandl) # API for downloading the data
library(keras) # To train the LSTM model
library(randomForest) # To implement random forests
library(forecast) # To assess predictions and compare them to the real test set
library(aTSA)
library(xgboost)
library(e1071)
library(superml)
library(lmtest)
library(rfUtilities)
set.seed(177125)
test_list <- "abc"
test_list <- "abc"
randomnum <- 1
test_list <- "abc"
randomnum <- 1
print(test_list)
randomnum <- randomnum + 1
print(randomnum)
print(randomnum)
test_list <- "abc"
randomnum <- 1
print(test_list)
randomnum <- randomnum + 1
print(randomnum)

---
title: title: "Has Data Science Shown Financial Markets are Not Efficient?"
output: html_document
author: "Karan Garg"
---

```{r setup, include=FALSE}
# Run once for installation
# Quandl API key: rTCfeqfv2pbfQG-uk-af
# install.packages("Quandl")
# install.packages("keras")
# install_keras()
# install.packages("tensorflow")
# install.packages("tsibble")
# install.packages("randomforest")
# install.packages("forecast")
# install.packages("aTSA)
# install.packages("xgboost")
# install.packages("superml")
# install.packages("rfUtilities")

knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) # For loading the generally needed packages, dplyr, ggplot2 etc
library(tsibble) # Extension of the tidyverse to time-series data
library(Quandl) # API for downloading the data
library(keras) # To train the LSTM model
library(randomForest) # To implement random forests
library(forecast) # To assess predictions and compare them to the real test set
library(aTSA)
library(xgboost)
library(e1071)
library(superml)
library(lmtest)
library(rfUtilities)
library(tfruns)
set.seed(177125)
```

```{r}
Quandl.api_key('rTCfeqfv2pbfQG-uk-af')
hsbc_tib <- Quandl('HKEX/00005', column_index = "1") %>% 
  as_tsibble(index="Date")

names(hsbc_tib)[2] <- "Price"
dates <- seq(as.Date("2014-02-21"), as.Date("2021-05-07"), by = "day")
hsbc_ts <- as.ts(hsbc_tib, start = c(2014, as.numeric(format(dates[1], "%j"))), frequency=365)
```

```{r}
ImputeMissing <- function(ts){
  df <- data.frame(ts)
#  Missing <- integer(nrow(df))
#  df = cbind(df, Missing)
  for(i in 1:nrow(df)){
    if(is.na(df[i, 1])){
      df[i, 1] <- df[i-1, 1]
#      df[i, 2] <- 1
    }
  }
  dates_formatted <- data.frame(dates)
  df <- cbind(df, dates_formatted)
  names(df)[1] <- "Price"
  names(df)[2] <- "Date"
  tib_new <- as_tsibble(df, index="Date") 
#                  start = c(2014, 32),
#                  frequency=365)
  
  return(tib_new)
}
```

```{r}
hsbc_tib <- ImputeMissing(hsbc_ts)
hsbc_ts <- as.ts(hsbc_tib, start = c(2014, as.numeric(format(dates[1], "%j"))), frequency=365)
```

```{r}
hsbc_log_diff <- hsbc_ts %>%
  log() %>%
  diff(1)
```

```{r}
hsbc_lagged <- embed(hsbc_log_diff, 21)
split_num_val <- round(nrow(hsbc_lagged)*0.7)
split_num_train <- round(nrow(hsbc_lagged)*0.6)
hsbc_train <- data.frame(hsbc_lagged[1: split_num_train, ])
hsbc_val <- data.frame(hsbc_lagged[(split_num_train+1):split_num_val, ])
hsbc_test <- data.frame(hsbc_lagged[(split_num_val+1):nrow(hsbc_lagged), ])
X_train <- data.matrix(hsbc_train[, -1])
X_train_lstm <- array(X_train, c(dim(X_train), 1))
y_train <- hsbc_train[, 1]
X_val <- data.matrix(hsbc_val[, -1])
X_val_lstm <- array(X_val, c(dim(X_val), 1))
y_val <- hsbc_val[, 1]
X_test <- data.matrix(hsbc_test[, -1])
X_test_lstm <- array(X_test, c(dim(X_test), 1))
y_test <- hsbc_test[, 1] %>%
  cumsum() %>%
  exp()
y_test <- y_test * as.vector(tail(hsbc_ts, 1))
val_list <- list(X_val_lstm, y_val)
```

```{r}
linear <- lm(X1 ~ X2 + X3 + X4 + X5 + X6 + X7 + X8 + X9 + X10 + X11 + X12 + X13 + X14 + X15 + X16 + X17 + X18 + X19 + X20 + X21, data=hsbc_train)
summary(linear)
resettest(linear)
```

```{r}
linear_predicted <- predict.lm(linear, newdata = data.frame(hsbc_test)) %>% 
  cumsum() %>%
  exp()
linear_predicted <- linear_predicted * as.vector(tail(hsbc_ts, 1))
results <- data.frame(cbind(y_test, linear_predicted))
names(results)[1] <- "actual"
linear_accuracy <- forecast::accuracy(linear_predicted, y_test)
```

```{r}
rf <- randomForest(X_train, y_train,
                   xtest=X_val, ytest=y_val,
                   keep.forest = TRUE)
rf_cv <- rf.crossValidation(rf, X_train, y_train,
                            bootstrap=FALSE, xtest=data.frame(X_val), ytest=y_val,
                            keep.forest = TRUE)
```

```{r}
rf_cv_predicted <- predict(rf, X_test) %>%
  cumsum() %>%
  exp()
rf_cv_predicted <- rf_cv_predicted * as.vector(tail(hsbc_ts, 1))
results <- data.frame(cbind(results, rf_cv_predicted))
head(results)
rf_accuracy <- forecast::accuracy(rf_cv_predicted, y_test)
```

```{r}
xgb <- XGBTrainer$new(objective="reg:squarederror")
xgb_gs <- GridSearchCV$new(trainer=xgb,
                           parameters=list(learning_rate=seq(from=0.1, to=0.5, by=0.05),
                                           max_depth=seq(from=3, to=10, by=1),
                                           subsample=seq(from=0.4, to=1, by=0.1),
                                           n_estimators=seq(from=50, to=300, by=50)),
                           n_folds=5,
                           scoring="rmse")
xgb_gs$fit(hsbc_train, "X1")
```

```{r}
xgb_gs$best_iteration()

#$learning_rate
#[1] 0.5

#$max_depth
#[1] 8

#$subsample
#[1] 0.4

#$n_estimators
#[1] 250

#$rmse_avg
#[1] 0.01427531

#$rmse_sd
#[1] 0.001181882
```

```{r}
xgb_tuned <- xgboost(data=X_train,
                     label=y_train,
                     nrounds=120,
                     params=list(eta=0.5,
                                 max_depth=8,
                                 subsample=0.4,
                                 n_estimators=250))
```

```{r}
xgb_tuned_predicted <- predict(xgb_tuned, X_test) %>%
  cumsum() %>%
  exp()
xgb_tuned_predicted <-xgb_tuned_predicted * as.vector(tail(hsbc_ts, 1))
```

```{r}
results <- data.frame(cbind(results, xgb_tuned_predicted))
head(results)
xgb_accuracy <- forecast::accuracy(xgb_tuned_predicted, y_test)
```
```{r}
lstm_parameters <- list(units=seq(from=1, to=32, by=1),
                        dropout=seq(from=0.1, to=0.9, by=0.1))
```

```{r}
runs <- tuning_runs("lstm.R", flags=lstm_parameters, sample=0.5)
ls_runs(order = metric_val_mean_squared_error, decreasing= FALSE)
```

```{r}
lstm <- keras_model_sequential() %>%
  layer_lstm(units=16, 
             activation="tanh", #Default actiavtion for LSTM
             return_sequences = FALSE, #Only one LSTM layer hence sequence of outputs not needed
             input_shape = dim(X_train_lstm)[-1]) %>% #The layer takes as an input 20 timesteps (lags) and 1 feature
  layer_dropout(0.2) %>%
  layer_dense(units=1) #Linear activation used rather than RELu/SELu as output can be positive or negative
```

```{r}
lstm %>% compile(optimizer="nadam", loss="mean_squared_error")
```

```{r}
lstm_model <- lstm %>% fit(x=X_train_lstm,
                           y=y_train,
                           batch_size=32,
                           epochs=100,
                           validation_data=val_list,
                           shuffle=FALSE)
```

```{r}
plot(lstm_model)
```

```{r}
lstm_predicted <- predict(lstm, X_test_lstm) %>%
  cumsum() %>%
  exp()
lstm_predicted <-lstm_predicted * as.vector(tail(hsbc_ts, 1))
lstm_accuracy <- forecast::accuracy(lstm_predicted, y_test)
print(lstm_accuracy)
```